# Docker Compose for The Plugs Production Environment
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: the_plugs_postgres_prod
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-the_plugs}
      POSTGRES_USER: ${POSTGRES_USER:-the_plugs_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./deployment/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    networks:
      - the_plugs_prod_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-the_plugs_user} -d ${POSTGRES_DB:-the_plugs}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis Cache & Message Broker
  redis:
    image: redis:7-alpine
    container_name: the_plugs_redis_prod
    command: redis-server /etc/redis/redis.conf
    volumes:
      - redis_prod_data:/data
      - ./deployment/redis/redis.conf:/etc/redis/redis.conf:ro
    networks:
      - the_plugs_prod_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # The Plugs API Application
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: the_plugs_api_prod
    environment:
      # Application
      ENVIRONMENT: production
      DEBUG: "false"
      APP_NAME: "The Plugs API"
      HOST: 0.0.0.0
      PORT: 8000
      
      # Database
      DATABASE_URL: postgresql://${POSTGRES_USER:-the_plugs_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-the_plugs}
      DATABASE_POOL_SIZE: 50
      DATABASE_MAX_OVERFLOW: 100
      DATABASE_ECHO: "false"
      
      # Redis
      REDIS_URL: redis://redis:6379/0
      
      # Celery
      CELERY_BROKER_URL: redis://redis:6379/1
      CELERY_RESULT_BACKEND: redis://redis:6379/2
      
      # Security
      SECRET_KEY: ${SECRET_KEY}
      JWT_ACCESS_TOKEN_EXPIRE_MINUTES: ${JWT_ACCESS_TOKEN_EXPIRE_MINUTES:-15}
      JWT_REFRESH_TOKEN_EXPIRE_DAYS: ${JWT_REFRESH_TOKEN_EXPIRE_DAYS:-7}
      
      # CORS
      CORS_ORIGINS: ${CORS_ORIGINS:-*}
      CORS_CREDENTIALS: ${CORS_CREDENTIALS:-true}
      CORS_METHODS: ${CORS_METHODS:-*}
      CORS_HEADERS: ${CORS_HEADERS:-*}
      
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: json
      
      # File uploads (500MB default - supports large videos)
      MAX_FILE_SIZE: ${MAX_FILE_SIZE:-524288000}
      UPLOAD_PATH: /app/uploads
      
      # Email
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USERNAME: ${SMTP_USERNAME}
      SMTP_PASSWORD: ${SMTP_PASSWORD}
      SMTP_USE_TLS: ${SMTP_USE_TLS:-true}
      
    expose:
      - "8000"
    volumes:
      - uploads_prod_data:/app/uploads:rw
      - logs_prod_data:/app/logs:rw
    networks:
      - the_plugs_prod_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # Nginx Load Balancer
  nginx:
    image: nginx:alpine
    container_name: the_plugs_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./deployment/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./deployment/nginx/ssl:/etc/nginx/ssl:ro
      - uploads_prod_data:/app/uploads:ro
    networks:
      - the_plugs_prod_network
    depends_on:
      - api
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Celery Worker
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: the_plugs_celery_worker_prod
    command: celery -A app.workers.celery_app worker --loglevel=info --concurrency=8 --max-tasks-per-child=1000
    environment:
      # Application
      ENVIRONMENT: production
      
      # Database
      DATABASE_URL: postgresql://${POSTGRES_USER:-the_plugs_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-the_plugs}
      
      # Redis
      REDIS_URL: redis://redis:6379/0
      
      # Celery
      CELERY_BROKER_URL: redis://redis:6379/1
      CELERY_RESULT_BACKEND: redis://redis:6379/2
      
      # Security
      SECRET_KEY: ${SECRET_KEY}
      
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: json
      
      # Email
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USERNAME: ${SMTP_USERNAME}
      SMTP_PASSWORD: ${SMTP_PASSWORD}
      SMTP_USE_TLS: ${SMTP_USE_TLS:-true}
      
    volumes:
      - uploads_prod_data:/app/uploads:rw
      - logs_prod_data:/app/logs:rw
    networks:
      - the_plugs_prod_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # Celery Beat (Scheduler)
  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: the_plugs_celery_beat_prod
    command: celery -A app.workers.celery_app beat --loglevel=info
    environment:
      # Application
      ENVIRONMENT: production
      
      # Database
      DATABASE_URL: postgresql://${POSTGRES_USER:-the_plugs_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-the_plugs}
      
      # Redis
      REDIS_URL: redis://redis:6379/0
      
      # Celery
      CELERY_BROKER_URL: redis://redis:6379/1
      CELERY_RESULT_BACKEND: redis://redis:6379/2
      
      # Security
      SECRET_KEY: ${SECRET_KEY}
      
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: json
      
    volumes:
      - logs_prod_data:/app/logs:rw
    networks:
      - the_plugs_prod_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# Networks
networks:
  the_plugs_prod_network:
    driver: bridge
    name: the_plugs_prod_network

# Volumes
volumes:
  postgres_prod_data:
    name: the_plugs_postgres_prod_data
  redis_prod_data:
    name: the_plugs_redis_prod_data
  uploads_prod_data:
    name: the_plugs_uploads_prod_data
  logs_prod_data:
    name: the_plugs_logs_prod_data


